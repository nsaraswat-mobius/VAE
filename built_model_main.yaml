name: Initialize VAE Model
description: Initializes the VAE model for failure signature anomaly detection.
inputs:
  - {name: config, type: String}
outputs:
  - {name: model, type: Model}
implementation:
  container:
    image: nikhilv215/nesy-factory:v22
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import json
        import os
        import pickle
        import sys
        import torch
        
        from nesy_factory.VAE.standard_vae import StandardVAE
        from nesy_factory.VAE.beta_vae import BetaVAE
        from nesy_factory.VAE.conditional_vae import ConditionalVAE

        parser = argparse.ArgumentParser()
        parser.add_argument('--config', type=str, required=True)
        parser.add_argument('--model', type=str, required=True)
        args = parser.parse_args()

        config = json.loads(args.config)

        # Get input dimension from config - use actual processed dimension
        if 'processed_input_dim' in config:
            # Use the actual dimension from preprocessing step
            input_dim = config['processed_input_dim']
            print(f"Using processed input dimension: {input_dim}")
        elif 'input_dim' in config:
            input_dim = config['input_dim']
            print(f"Using configured input dimension: {input_dim}")
        elif 'feature_columns' in config:
            # This is just an estimate - actual may be higher due to one-hot encoding
            base_features = len(config['feature_columns'])
            # Assume worst case: all categorical with 10 categories each
            input_dim = base_features * 10  # Conservative estimate
            print(f"Warning: Estimating input dimension as {input_dim} based on {base_features} features")
            print("Note: Actual dimension may differ due to one-hot encoding")
        else:
            # Default fallback - this should not happen in production
            input_dim = 50  # Increased default to handle typical one-hot encoded data
            print(f"Warning: input_dim not found in config, using default value of {input_dim}")
        
        print(f"Final input dimension: {input_dim}")

        # Build VAE model configuration
        model_config = {
            'input_dim': input_dim,
            'latent_dim': config.get('latent_dim', 16),
            'hidden_dim': config.get('hidden_dim', 64),
            'num_layers': config.get('num_layers', 2),
            'dropout': config.get('dropout', 0.1),
            'beta': config.get('beta', 1.0),  # For Beta-VAE
            'optimizer': 'adam',
            'learning_rate': config.get('learning_rate', 0.001),
            'epochs': config.get('epochs', 100),
            'loss_function': config.get('loss_function', 'ELBO (reconstruction MSE + KL divergence)')
        }

        print(f"Model configuration: {model_config}")

        # Initialize the appropriate VAE model based on model_type
        model_type = config.get('model_type', 'VAE')
        
        if model_type == 'StandardVAE' or model_type == 'VAE':
            model_obj = StandardVAE(model_config)
            print("Initialized Standard VAE")
        elif model_type == 'BetaVAE':
            model_obj = BetaVAE(model_config)
            print(f"Initialized Beta-VAE with beta={model_config['beta']}")
        elif model_type == 'ConditionalVAE':
            # For conditional VAE, we might need additional configuration
            num_classes = config.get('num_classes', 10)
            model_config['num_classes'] = num_classes
            model_obj = ConditionalVAE(model_config)
            print(f"Initialized Conditional VAE with {num_classes} classes")
        else:
            raise ValueError(f"Invalid VAE model type specified: {model_type}")

        # Save the model
        os.makedirs(os.path.dirname(args.model), exist_ok=True)
        with open(args.model, "wb") as f:
            pickle.dump(model_obj, f)

        print(f"Saved {model_type} model to {args.model}")
        print(f"Model parameters: {sum(p.numel() for p in model_obj.parameters() if p.requires_grad)} trainable parameters")
    args:
      - --config
      - {inputValue: config}
      - --model
      - {outputPath: model}
