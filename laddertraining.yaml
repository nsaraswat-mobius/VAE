name: train_ladder_vae_model
description: Trains Ladder VAE model on preprocessed World Bank data with hierarchical loss
inputs:
  - {name: preprocessed_path, type: String, description: "Path to preprocessed 2D tensor (.pt file)"}
  - {name: model_path, type: String, description: "Path to model checkpoint (.pt file)"}
  - {name: config_path, type: String, description: "Path to model config (JSON file)"}
  - {name: learning_rate, type: Float, description: "Learning rate", default: "1e-3"}
  - {name: batch_size, type: Integer, description: "Batch size for training", default: "32"}
  - {name: epochs, type: Integer, description: "Number of training epochs", default: "50"}
  - {name: kl_weight, type: Float, description: "KL divergence weight in loss", default: "1.0"}
  - {name: validation_split, type: Float, description: "Validation split ratio", default: "0.1"}
outputs:
  - {name: trained_model_path, type: String, description: "Path to trained model checkpoint"}
  - {name: metrics_path, type: String, description: "Path to training metrics JSON"}

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v2
    command:
      - python3
      - -u
      - -c
      - |
        import argparse
        import os
        import json
        import torch
        import torch.nn as nn
        import torch.nn.functional as F
        import torch.optim as optim
        from torch.utils.data import TensorDataset, DataLoader
        
        # ===== EMBEDDED LADDER VAE MODULE =====
        class LadderVAE(nn.Module):
            def __init__(self, input_dim, level1_latent=32, level2_latent=16, 
                         level1_hidden=128, level2_hidden=64, beta=1.0):
                super(LadderVAE, self).__init__()
                self.level1_latent = level1_latent
                self.level2_latent = level2_latent
                self.level1_hidden = level1_hidden
                self.level2_hidden = level2_hidden
                self.beta = beta
                
                # Encoder Level 1
                self.enc1_fc = nn.Linear(input_dim, level1_hidden)
                self.enc1_mu = nn.Linear(level1_hidden, level1_latent)
                self.enc1_logvar = nn.Linear(level1_hidden, level1_latent)
                
                # Encoder Level 2
                self.enc2_fc = nn.Linear(level1_latent, level2_hidden)
                self.enc2_mu = nn.Linear(level2_hidden, level2_latent)
                self.enc2_logvar = nn.Linear(level2_hidden, level2_latent)
                
                # Decoder Level 2
                self.dec2_fc = nn.Sequential(
                    nn.Linear(level2_latent, level2_hidden),
                    nn.ReLU(),
                    nn.Linear(level2_hidden, level1_latent)
                )
                
                # Decoder Level 1
                self.dec1_fc = nn.Sequential(
                    nn.Linear(level1_latent, level1_hidden),
                    nn.ReLU(),
                    nn.Linear(level1_hidden, input_dim)
                )
            
            def encode(self, x):
                h1 = F.relu(self.enc1_fc(x))
                mu1 = self.enc1_mu(h1)
                logvar1 = self.enc1_logvar(h1)
                std1 = torch.exp(0.5 * logvar1)
                z1 = mu1 + std1 * torch.randn_like(std1)
                
                h2 = F.relu(self.enc2_fc(z1))
                mu2 = self.enc2_mu(h2)
                logvar2 = self.enc2_logvar(h2)
                std2 = torch.exp(0.5 * logvar2)
                z2 = mu2 + std2 * torch.randn_like(std2)
                
                return [mu1, mu2], [logvar1, logvar2], [z1, z2]
            
            def decode(self, z_list):
                z1, z2 = z_list
                z1_recon = self.dec2_fc(z2)
                x_recon = self.dec1_fc(z1_recon)
                return x_recon
            
            def forward(self, x):
                mus, logvars, z_list = self.encode(x)
                recon = self.decode(z_list)
                return recon, mus, logvars
            
            def vae_loss(self, x, recon_x, mus, logvars, reduction='mean'):
                recon_loss = F.mse_loss(recon_x, x, reduction=reduction)
                kl_loss = 0
                for mu, logvar in zip(mus, logvars):
                    level_kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)
                    if reduction == 'mean':
                        level_kl = level_kl.mean()
                    kl_loss += level_kl
                return recon_loss + self.beta * kl_loss
        
        def create_ladder_vae(input_dim, level1_latent=32, level2_latent=16, 
                              level1_hidden=128, level2_hidden=64, beta=1.0):
            return LadderVAE(input_dim, level1_latent, level2_latent, 
                           level1_hidden, level2_hidden, beta)
        # ===== END EMBEDDED LADDER VAE =====
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--preprocessed_path', type=str, required=True)
        parser.add_argument('--model_path', type=str, required=True)
        parser.add_argument('--config_path', type=str, required=True)
        parser.add_argument('--learning_rate', type=float, default=1e-3)
        parser.add_argument('--batch_size', type=int, default=32)
        parser.add_argument('--epochs', type=int, default=50)
        parser.add_argument('--kl_weight', type=float, default=1.0)
        parser.add_argument('--validation_split', type=float, default=0.1)
        parser.add_argument('--trained_model_path', type=str, required=True)
        parser.add_argument('--metrics_path', type=str, required=True)
        args = parser.parse_args()
        
        print("=" * 70)
        print("TRAINING LADDER VAE")
        print("=" * 70)
        
        try:
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            print(f"\\nDevice: {device}")
            
            # Helper function to resolve Kubeflow artifact paths
            def resolve_path(input_path):
                print(f"    Resolving path: {input_path}")
                
                # If it's a file, use it directly
                if os.path.isfile(input_path):
                    print(f"     Direct file: {input_path}")
                    return input_path
                
                # If it's a directory
                if os.path.isdir(input_path):
                    # First check for 'data' file (Kubeflow style)
                    data_file = os.path.join(input_path, "data")
                    if os.path.exists(data_file):
                        with open(data_file, 'r') as f:
                            actual_path = f.read().strip()
                        print(f"     From data file: {actual_path}")
                        return actual_path
                    
                    # If no data file, look for the actual file in the directory
                    # For config, look for .json files
                    if 'config' in input_path or 'json' in input_path:
                        json_files = [f for f in os.listdir(input_path) if f.endswith('.json')]
                        if json_files:
                            actual_path = os.path.join(input_path, json_files[0])
                            print(f"     Found JSON: {actual_path}")
                            return actual_path
                    
                    # For model, look for .pt files
                    if 'model' in input_path or 'pt' in input_path:
                        pt_files = [f for f in os.listdir(input_path) if f.endswith('.pt')]
                        if pt_files:
                            actual_path = os.path.join(input_path, pt_files[0])
                            print(f"     Found PT: {actual_path}")
                            return actual_path
                    
                    # List directory contents for debugging
                    print(f"    Directory contents: {os.listdir(input_path)}")
                
                # If we get here, return the original path and hope for the best
                print(f"     Using original: {input_path}")
                return input_path
            
            # [1] Load configuration
            print("\\n[1/5] Loading config...")
            config_file = resolve_path(args.config_path)
            print(f"    Loading config from: {config_file}")
            
            with open(config_file, 'r') as f:
                config = json.load(f)
            print(f"    Input: {config['input_dim']}, Latent: {config['level1_latent']}/{config['level2_latent']}")
            
            # [2] Load preprocessed data
            print("\\n[2/5] Loading data...")
            data_file = resolve_path(args.preprocessed_path)
            print(f"    Loading data from: {data_file}")
            
            preprocessed_data = torch.load(data_file, weights_only=False)
            
            num_samples, num_features = preprocessed_data.shape
            print(f"    Shape: {preprocessed_data.shape} (samples Ã— features)")
            
            # [3] Create and load model
            print("\\n[3/5] Loading model...")
            model = create_ladder_vae(
                input_dim=config['input_dim'],
                level1_latent=config['level1_latent'],
                level2_latent=config['level2_latent'],
                level1_hidden=config['level1_hidden'],
                level2_hidden=config['level2_hidden'],
                beta=config.get('beta', args.kl_weight)
            )
            
            # Resolve checkpoint path
            checkpoint_file = resolve_path(args.model_path)
            print(f"    Loading checkpoint from: {checkpoint_file}")
            
            model.load_state_dict(torch.load(checkpoint_file, map_location=device, weights_only=False))
            model = model.to(device)
            model.train()
            print(f"    Model: {sum(p.numel() for p in model.parameters()):,} params")
            
            # [4] Prepare data loaders
            print("\\n[4/5] Preparing loaders...")
            val_size = int(num_samples * args.validation_split)
            train_size = num_samples - val_size
            
            train_data = preprocessed_data[:train_size].to(device)
            val_data = preprocessed_data[train_size:].to(device)
            
            train_dataset = TensorDataset(train_data)
            val_dataset = TensorDataset(val_data)
            
            train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)
            val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)
            
            print(f"    Train: {train_size}, Val: {val_size}, Batch: {args.batch_size}")
            
            # [5] Training loop
            print("\\n[5/5] Training model...")
            optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)
            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)
            
            metrics = {
                "train_loss": [],
                "train_recon": [],
                "train_kl": [],
                "val_loss": [],
                "val_recon": [],
                "val_kl": [],
                "best_val_loss": float('inf'),
                "best_epoch": 0
            }
            
            best_val_loss = float('inf')
            best_model_state = None
            
            for epoch in range(args.epochs):
                # Training phase
                train_loss_total = 0.0
                train_recon_total = 0.0
                train_kl_total = 0.0
                
                for batch_idx, (batch_x,) in enumerate(train_loader):
                    batch_x = batch_x.to(device)
                    
                    optimizer.zero_grad()
                    
                    # Forward pass
                    x_recon, mus, logvars = model(batch_x)
                    
                    # Compute loss using model's vae_loss method with per-level KL
                    loss = model.vae_loss(batch_x, x_recon, mus, logvars, reduction='mean')
                    
                    # Reconstruction loss
                    recon_loss = F.mse_loss(x_recon, batch_x, reduction='mean')
                    
                    # Per-level KL divergence
                    kl_loss = 0
                    for mu, logvar in zip(mus, logvars):
                        kl_loss += -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
                    
                    loss.backward()
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    optimizer.step()
                    
                    train_loss_total += loss.item()
                    train_recon_total += recon_loss.item()
                    train_kl_total += kl_loss.item()
                
                avg_train_loss = train_loss_total / len(train_loader)
                avg_train_recon = train_recon_total / len(train_loader)
                avg_train_kl = train_kl_total / len(train_loader)
                
                # Validation phase
                model.eval()
                val_loss_total = 0.0
                val_recon_total = 0.0
                val_kl_total = 0.0
                
                with torch.no_grad():
                    for batch_idx, (batch_x,) in enumerate(val_loader):
                        batch_x = batch_x.to(device)
                        
                        x_recon, mus, logvars = model(batch_x)
                        
                        loss = model.vae_loss(batch_x, x_recon, mus, logvars, reduction='mean')
                        recon_loss = F.mse_loss(x_recon, batch_x, reduction='mean')
                        
                        kl_loss = 0
                        for mu, logvar in zip(mus, logvars):
                            kl_loss += -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
                        
                        val_loss_total += loss.item()
                        val_recon_total += recon_loss.item()
                        val_kl_total += kl_loss.item()
                
                avg_val_loss = val_loss_total / len(val_loader)
                avg_val_recon = val_recon_total / len(val_loader)
                avg_val_kl = val_kl_total / len(val_loader)
                
                # Save best model
                if avg_val_loss < best_val_loss:
                    best_val_loss = avg_val_loss
                    best_model_state = model.state_dict().copy()
                    metrics["best_epoch"] = epoch + 1
                    metrics["best_val_loss"] = best_val_loss
                
                # Learning rate scheduling
                scheduler.step(avg_val_loss)
                
                # Record metrics
                metrics["train_loss"].append(avg_train_loss)
                metrics["train_recon"].append(avg_train_recon)
                metrics["train_kl"].append(avg_train_kl)
                metrics["val_loss"].append(avg_val_loss)
                metrics["val_recon"].append(avg_val_recon)
                metrics["val_kl"].append(avg_val_kl)
                
                model.train()
                
                if (epoch + 1) % 5 == 0 or epoch == 0:
                    print(f"   E{epoch+1:3d} | Train: {avg_train_loss:.4f} | Val: {avg_val_loss:.4f}")
            
            # [6] Save trained model and metrics
            print("\\n[6/5] Saving model and metrics...")
            os.makedirs(args.trained_model_path, exist_ok=True)
            os.makedirs(args.metrics_path, exist_ok=True)
            
            trained_model_file = os.path.join(args.trained_model_path, "ladder_vae_trained.pt")
            torch.save(best_model_state, trained_model_file)
            with open(os.path.join(args.trained_model_path, "data"), "w") as f:
                f.write(trained_model_file)
            
            metrics_file = os.path.join(args.metrics_path, "training_metrics.json")
            with open(metrics_file, 'w') as f:
                json.dump(metrics, f, indent=2)
            with open(os.path.join(args.metrics_path, "data"), "w") as f:
                f.write(metrics_file)
            
            print(f"    Model: {trained_model_file}")
            print(f"    Metrics: {metrics_file}")
            print(f"\\n{'='*70}\\n TRAINING COMPLETE | Best Epoch: {metrics['best_epoch']} | Best Loss: {metrics['best_val_loss']:.4f}\\n{'='*70}")
            
        except Exception as e:
            print(f"Error during training: {str(e)}")
            import traceback
            traceback.print_exc()
            exit(1)
    
    args:
      - --preprocessed_path
      - {inputPath: preprocessed_path}
      - --model_path
      - {inputPath: model_path}
      - --config_path
      - {inputPath: config_path}
      - --learning_rate
      - {inputValue: learning_rate}
      - --batch_size
      - {inputValue: batch_size}
      - --epochs
      - {inputValue: epochs}
      - --kl_weight
      - {inputValue: kl_weight}
      - --validation_split
      - {inputValue: validation_split}
      - --trained_model_path
      - {outputPath: trained_model_path}
      - --metrics_path
      - {outputPath: metrics_path}
