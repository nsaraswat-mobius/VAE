name: Generate Static VAE URLs
description: Generates static hardcoded URLs for VAE model, handler.py, and config files for KServe inference deployment.
inputs:
  - {name: trained_model, type: Model, description: "Trained VAE PyTorch model file (for validation only)"}
outputs:
  - {name: vae_model_url, type: String, description: "Static URL for trained_vae_model.pth"}
  - {name: handler_url, type: String, description: "Static URL for handler.py"}
  - {name: config_url, type: String, description: "Static URL for vae_config.properties"}
implementation:
  container:
    image: nikhilv215/nesy-factory:v22
    command:
      - sh
      - -c
      - |
        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet torch || \
        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet torch --user
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import os
        import torch
        import sys
        from datetime import datetime
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--trained_model', type=str, required=True)
        parser.add_argument('--vae_model_url', type=str, required=True)
        parser.add_argument('--handler_url', type=str, required=True)
        parser.add_argument('--config_url', type=str, required=True)
        
        args = parser.parse_args()
        
        print("Generating Static VAE URLs for KServe")
        print("Model path:", args.trained_model)
        
        # Static hardcoded URLs - modify these to point to your actual CDN/storage
        base_url = "https://storage.googleapis.com/vae-signature-failure-models/vae-models/v1.0/signature-failure"
        model_url = f"{base_url}/trained_vae_model.pth"
        handler_url = f"{base_url}/handler.py"
        config_url = f"{base_url}/vae_config.properties"
        
        try:
            # Handle model path - could be file or directory
            model_path = args.trained_model
            if os.path.isdir(model_path):
                # Look for .pth, .pt, or .ckpt files in the directory
                model_files = [f for f in os.listdir(model_path) 
                             if f.endswith(('.pth', '.pt', '.ckpt')) and not f.startswith('.')]
                if model_files:
                    # Prefer .pth files, otherwise take the first available
                    pth_files = [f for f in model_files if f.endswith('.pth')]
                    if pth_files:
                        model_path = os.path.join(model_path, pth_files[0])
                    else:
                        model_path = os.path.join(model_path, model_files[0])
                    print(f"Found model file: {model_path}")
                else:
                    print(f"Warning: No model files found in {model_path}")
                    model_path = None
            
            # Validate model file if found
            if model_path and os.path.exists(model_path):
                try:
                    checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
                    print("VAE model validation successful")
                    
                    # Extract model info
                    if 'model_state_dict' in checkpoint:
                        param_count = len(checkpoint['model_state_dict'])
                        print(f"   Model contains state_dict with {param_count} parameters")
                    elif 'state_dict' in checkpoint:
                        param_count = len(checkpoint['state_dict'])
                        print(f"   Model contains state_dict with {param_count} parameters")
                    else:
                        print("   Model contains direct weights")
                        
                    # Check for training metadata
                    if 'epoch' in checkpoint:
                        print(f"   Training epoch: {checkpoint['epoch']}")
                    if 'loss' in checkpoint:
                        print(f"   Training loss: {checkpoint['loss']:.4f}")
                        
                except Exception as e:
                    print(f"Warning: Model validation failed: {str(e)}")
            else:
                print("Warning: No valid model file found - continuing with URL generation")
            
            # Create output directories and write static URLs to output files
            print("Creating output directories...")
            
            # Create directories for each output
            for output_path in [args.vae_model_url, args.handler_url, args.config_url]:
                os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # Write URLs to files
            with open(args.vae_model_url, 'w') as f:
                f.write(model_url)
            print(f"Model URL written to: {args.vae_model_url}")
            
            with open(args.handler_url, 'w') as f:
                f.write(handler_url)
            print(f"Handler URL written to: {args.handler_url}")
                
            with open(args.config_url, 'w') as f:
                f.write(config_url)
            print(f"Config URL written to: {args.config_url}")
            
            # Display summary
            print("")
            print("=" * 60)
            print("STATIC VAE URLs GENERATED SUCCESSFULLY!")
            print("=" * 60)
            print("")
            print("GENERATED URLs FOR KSERVE INFERENCE:")
            print("-" * 40)
            print(f"Model URL:")
            print(f"   {model_url}")
            print("")
            print(f"Handler URL:")
            print(f"   {handler_url}")
            print("")
            print(f"Config URL:")
            print(f"   {config_url}")
            print("")
            print("=" * 60)
            print("NEXT STEPS:")
            print("=" * 60)
            print("1. Ensure your model files are uploaded to these URLs")
            print("2. Use these URLs in your KServe InferenceService YAML")
            print("3. Verify the files are accessible via HTTP")
            print("")
            print("Example KServe usage:")
            print(f"   - model: {model_url}")
            print(f"   - handler: {handler_url}") 
            print(f"   - config: {config_url}")
            print("=" * 60)
            
        except Exception as e:
            print(f"Failed to generate VAE URLs: {str(e)}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
    args:
      - --trained_model
      - {inputPath: trained_model}
      - --vae_model_url
      - {outputPath: vae_model_url}
      - --handler_url
      - {outputPath: handler_url}
      - --config_url
      - {outputPath: config_url}
