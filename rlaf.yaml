name: VAE RLAF Loop
description: Triggers the DQN RLAF pipeline in a loop to optimize VAE model hyperparameters using continual learning, controlled by a pierce_or_not flag.
inputs:
  - {name: trained_model, type: Model}
  - {name: init_metrics, type: Metrics}
  - {name: data_path, type: Dataset}
  - {name: config, type: String}
  - {name: domain, type: String}
  - {name: schema_id, type: String}
  - {name: model_id, type: String}
  - {name: dqn_pipeline_id, type: String}
  - {name: pipeline_domain, type: String}
  - {name: dqn_experiment_id, type: String}
  - {name: access_token, type: string}
  - {name: tasks, type: Dataset}
outputs:
  - {name: rlaf_output, type: Dataset}
  - {name: retrained_model, type: Model}
implementation:
  container:
    image: nikhilv215/nesy-factory:v22
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import torch.nn as nn
        import torch.optim as optim
        import torch.nn.functional as F
        import os
        import json
        import argparse
        import requests
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        import time
        import pickle
        from typing import List, Dict, Any
        import numpy as np
        from torch.utils.data import DataLoader, Dataset, Subset
        import random
        import copy

        class ProcessedVAEDataset(Dataset):
            def __init__(self, data, labels, vae_type):
                self.data = data
                self.labels = labels
                self.vae_type = vae_type
                self.class_mapping = {}

            def __len__(self):
                return len(self.data)

            def __getitem__(self, idx):
                return self.data[idx], self.labels[idx]

        class DataWrapper:
            def __init__(self, data_dict):
                self.__dict__.update(data_dict)

        class ContinualVAETrainer:
            def __init__(self, config):
                self.config = config
                self.results = {}
                self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

            def train_continual_vae(self, tasks, model, strategies=['naive', 'replay', 'regularized']):
                results = {}
                
                for strategy_name in strategies:
                    print(f'Training VAE with {strategy_name.upper()} strategy')
                    strategy_results = self._train_single_strategy(tasks, strategy_name, model)
                    results[strategy_name] = strategy_results
                    
                return results

            def _train_single_strategy(self, tasks, strategy_name, model):
                # Create fresh model copy for each strategy
                model_copy = copy.deepcopy(model).to(self.device)
                optimizer = optim.Adam(model_copy.parameters(), lr=self.config.get('learning_rate', 0.001))
                
                # Track metrics across tasks
                task_metrics = []
                all_task_performance = []
                previous_task_data = []
                
                print(f"Learning {len(tasks)} sequential VAE tasks")
                
                for task_idx, task_data in enumerate(tasks):
                    print(f"Learning Task {task_idx + 1}: {task_data['description']}")
                    
                    # Get data loaders for current task
                    train_loader = task_data['train_loader']
                    val_loader = task_data['val_loader']
                    
                    # Apply strategy-specific training
                    if strategy_name == 'naive':
                        training_loader = train_loader
                    elif strategy_name == 'replay':
                        if previous_task_data:
                            training_loader = self._create_replay_loader(train_loader, previous_task_data)
                        else:
                            training_loader = train_loader
                    elif strategy_name == 'regularized':
                        training_loader = train_loader
                        if task_idx > 0:
                            self._store_important_params(model_copy)
                    else:
                        training_loader = train_loader
                    
                    # Train VAE on current task
                    print(f"  Training VAE on Task {task_idx + 1}")
                    for epoch in range(self.config.get('epochs', 50)):
                        if strategy_name == 'regularized' and task_idx > 0:
                            loss = self._train_epoch_with_regularization(model_copy, optimizer, training_loader)
                        else:
                            loss = self._train_epoch(model_copy, optimizer, training_loader)
                        
                        if epoch % 10 == 0:
                            print(f"    Epoch {epoch:03d} | Loss: {loss:.4f}")
                    
                    # Store task data for potential replay
                    if strategy_name == 'replay':
                        previous_task_data.append(task_data)
                        if len(previous_task_data) > 3:
                            previous_task_data = previous_task_data[-3:]
                    
                    # Evaluate on current task
                    current_task_metrics = self._evaluate_vae(model_copy, val_loader)
                    task_metrics.append(current_task_metrics)
                    
                    print(f"    Task {task_idx + 1} VAE Loss: {current_task_metrics['vae_loss']:.4f}")
                    
                    # Evaluate on all previous tasks
                    task_performance = []
                    for eval_task_idx in range(task_idx + 1):
                        eval_val_loader = tasks[eval_task_idx]['val_loader']
                        eval_metrics = self._evaluate_vae(model_copy, eval_val_loader)
                        task_performance.append({
                            'task_id': int(eval_task_idx),
                            'vae_loss': float(eval_metrics['vae_loss']),
                            'reconstruction_loss': float(eval_metrics['reconstruction_loss']),
                            'kl_loss': float(eval_metrics['kl_loss']),
                            'description': str(tasks[eval_task_idx]['description'])
                        })
                    
                    all_task_performance.append(task_performance)
                    
                    if task_idx > 0:
                        print(f"Performance on previous tasks:")
                        for prev_task in task_performance[:-1]:
                            print(f"    Task {prev_task['task_id'] + 1}: Loss {prev_task['vae_loss']:.4f}")
                
                # Calculate continual learning metrics
                cl_metrics = self._calculate_continual_metrics(all_task_performance)
                
                # Calculate average metrics
                final_eval_metrics = []
                for i in range(len(tasks)):
                    metrics = self._evaluate_vae(model_copy, tasks[i]['val_loader'])
                    final_eval_metrics.append(metrics)
                
                avg_metrics = {}
                if final_eval_metrics:
                    for key in final_eval_metrics[0]:
                        # Ensure numeric values for averaging
                        numeric_values = []
                        for m in final_eval_metrics:
                            try:
                                if isinstance(m[key], (int, float)):
                                    numeric_values.append(float(m[key]))
                                else:
                                    # Try to convert string to float
                                    numeric_values.append(float(str(m[key])))
                            except (ValueError, TypeError):
                                print(f"Warning: Could not convert metric '{key}' value '{m[key]}' to numeric. Skipping.")
                                continue
                        
                        if numeric_values:
                            avg_metrics[key] = float(np.mean(numeric_values))
                        else:
                            avg_metrics[key] = 0.0

                results = {
                    'strategy': strategy_name,
                    'task_metrics': task_metrics,
                    'all_task_performance': all_task_performance,
                    'continual_metrics': cl_metrics,
                    'final_model': model_copy,
                    'average_eval_metrics': avg_metrics
                }
                
                return results

            def _train_epoch(self, model, optimizer, train_loader):
                model.train()
                total_loss = 0
                num_batches = 0
                
                for batch_data, batch_labels in train_loader:
                    batch_data = batch_data.to(self.device)
                    
                    optimizer.zero_grad()
                    
                    # VAE forward pass
                    if hasattr(model, 'vae_type') and model.vae_type == 'conditional_vae':
                        batch_labels = batch_labels.to(self.device)
                        outputs = model(batch_data, batch_labels)
                    elif hasattr(model, 'vae_type') and model.vae_type == 'vq_vae':
                        outputs = model(batch_data)
                        if isinstance(outputs, (tuple, list)) and len(outputs) >= 2:
                            recon_batch, vq_loss = outputs[0], outputs[1]
                            loss = F.mse_loss(recon_batch, batch_data) + vq_loss
                            loss.backward()
                            optimizer.step()
                            total_loss += loss.item()
                            num_batches += 1
                            continue
                    else:
                        outputs = model(batch_data)
                    
                    # Handle different output formats
                    if isinstance(outputs, dict):
                        # Handle dictionary output format
                        recon_batch = outputs.get('reconstruction', outputs.get('recon', outputs.get('x_recon', None)))
                        mu = outputs.get('mu', outputs.get('z_mean', outputs.get('mean', None)))
                        logvar = outputs.get('logvar', outputs.get('z_logvar', outputs.get('log_var', None)))
                        
                        if recon_batch is None:
                            print("Could not find reconstruction in dict output, skipping batch")
                            continue
                        if mu is None:
                            latent_dim = self.config.get('latent_dim', 128)
                            mu = torch.zeros(batch_data.size(0), latent_dim).to(self.device)
                        if logvar is None:
                            logvar = torch.zeros_like(mu)
                            
                    elif isinstance(outputs, (tuple, list)):
                        # Handle tuple/list output format
                        if len(outputs) == 3:
                            recon_batch, mu, logvar = outputs
                        elif len(outputs) == 2:
                            recon_batch, mu = outputs
                            logvar = torch.zeros_like(mu)
                        elif len(outputs) == 1:
                            recon_batch = outputs[0]
                            latent_dim = self.config.get('latent_dim', 128)
                            mu = torch.zeros(batch_data.size(0), latent_dim).to(self.device)
                            logvar = torch.zeros_like(mu)
                        else:
                            print(f"Unexpected tuple output format: {len(outputs)} outputs")
                            continue
                    else:
                        print(f"Unexpected output type: {type(outputs)}")
                        continue
                    
                    # VAE loss calculation
                    recon_loss = F.mse_loss(recon_batch, batch_data, reduction='sum')
                    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
                    
                    # Total VAE loss
                    beta = self.config.get('beta', 1.0)
                    loss = recon_loss + beta * kl_loss
                    
                    loss.backward()
                    optimizer.step()
                    
                    total_loss += loss.item()
                    num_batches += 1
                
                return float(total_loss / num_batches) if num_batches > 0 else 0.0

            def _train_epoch_with_regularization(self, model, optimizer, train_loader):
                base_loss = self._train_epoch(model, optimizer, train_loader)
                
                # Add regularization penalty
                reg_loss = 0.0
                reg_lambda = 0.1
                
                if hasattr(self, 'important_params'):
                    for name, param in model.named_parameters():
                        if name in self.important_params and param.requires_grad:
                            reg_loss += torch.sum((param - self.important_params[name]).pow(2)).item()
                
                total_loss = float(base_loss) + reg_lambda * float(reg_loss)
                return total_loss

            def _evaluate_vae(self, model, val_loader):
                model.eval()
                total_loss = 0
                total_recon_loss = 0
                total_kl_loss = 0
                num_samples = 0
                
                vae_type = getattr(model, 'vae_type', self.config.get('vae_type', 'standard_vae'))
                beta = self.config.get('beta', 1.0)
                
                print(f"Evaluating {vae_type} model...")
                with torch.no_grad():
                    for batch_idx, (batch_data, batch_labels) in enumerate(val_loader):
                        batch_data = batch_data.to(self.device)
                        batch_size = batch_data.size(0)
                        
                        try:
                            if vae_type == 'conditional_vae':
                                batch_labels = batch_labels.to(self.device)
                                outputs = model(batch_data, batch_labels)
                            elif vae_type == 'vq_vae':
                                outputs = model(batch_data)
                            else:
                                outputs = model(batch_data)
                            
                            # Handle different output formats (like evalve component)
                            if isinstance(outputs, dict):
                                # Handle dictionary output format
                                recon_batch = outputs.get('reconstruction', outputs.get('recon', outputs.get('x_recon', None)))
                                mu = outputs.get('mu', outputs.get('z_mean', outputs.get('mean', None)))
                                logvar = outputs.get('logvar', outputs.get('z_logvar', outputs.get('log_var', None)))
                                
                                if recon_batch is None:
                                    print("Could not find reconstruction in dict output, skipping batch")
                                    continue
                                if mu is None:
                                    latent_dim = self.config.get('latent_dim', 128)
                                    mu = torch.zeros(batch_size, latent_dim).to(self.device)
                                if logvar is None:
                                    logvar = torch.zeros_like(mu)
                                    
                            elif isinstance(outputs, (tuple, list)):
                                # Handle tuple/list output format
                                if vae_type == 'vq_vae':
                                    if len(outputs) >= 2:
                                        recon_batch, vq_loss = outputs[0], outputs[1]
                                        recon_loss = F.mse_loss(recon_batch, batch_data, reduction='sum')
                                        total_loss += (recon_loss + vq_loss).item()
                                        total_recon_loss += recon_loss.item()
                                        total_kl_loss += vq_loss.item()
                                        num_samples += batch_size
                                        continue
                                    else:
                                        print(f"Unexpected VQ-VAE output format: {len(outputs)} outputs")
                                        continue
                                else:
                                    if len(outputs) == 3:
                                        recon_batch, mu, logvar = outputs
                                    elif len(outputs) == 2:
                                        recon_batch, mu = outputs
                                        logvar = torch.zeros_like(mu)
                                    else:
                                        print(f"Unexpected tuple output format: {len(outputs)} outputs")
                                        recon_batch = outputs[0]
                                        latent_dim = self.config.get('latent_dim', 128)
                                        mu = torch.zeros(batch_size, latent_dim).to(self.device)
                                        logvar = torch.zeros_like(mu)
                            else:
                                print(f"Unexpected output type: {type(outputs)}")
                                continue
                            
                            # Compute VAE losses (same as evalve component)
                            if vae_type != 'vq_vae':
                                recon_loss = F.mse_loss(recon_batch, batch_data, reduction='sum')
                                kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
                                
                                if vae_type == 'beta_vae':
                                    loss = recon_loss + beta * kl_loss
                                else:
                                    loss = recon_loss + kl_loss
                                
                                total_loss += loss.item()
                                total_recon_loss += recon_loss.item()
                                total_kl_loss += kl_loss.item()
                                num_samples += batch_size
                                
                        except Exception as e:
                            print(f"Error in batch {batch_idx}: {e}")
                            continue
                
                # Calculate average metrics (same as evalve component)
                avg_loss = float(total_loss / num_samples) if num_samples > 0 else 0.0
                avg_recon_loss = float(total_recon_loss / num_samples) if num_samples > 0 else 0.0
                avg_kl_loss = float(total_kl_loss / num_samples) if num_samples > 0 else 0.0
                
                return {
                    'vae_loss': avg_loss,
                    'reconstruction_loss': avg_recon_loss,
                    'kl_loss': avg_kl_loss,
                    'num_samples': int(num_samples),
                    'model_type': str(vae_type)
                }

            def _create_replay_loader(self, current_loader, previous_task_data):
                # Simplified replay implementation
                return current_loader

            def _store_important_params(self, model):
                if not hasattr(self, 'important_params'):
                    self.important_params = {}
                
                for name, param in model.named_parameters():
                    if param.requires_grad:
                        self.important_params[name] = param.clone().detach()

            def _calculate_continual_metrics(self, all_task_performance):
                final_performance = all_task_performance[-1]
                
                # Safely extract numeric values for loss calculations
                loss_values = []
                for task in final_performance:
                    try:
                        loss_val = task['vae_loss']
                        if isinstance(loss_val, (int, float)):
                            loss_values.append(float(loss_val))
                        elif isinstance(loss_val, str):
                            loss_values.append(float(loss_val))
                        else:
                            loss_values.append(float(str(loss_val)))
                    except (ValueError, TypeError):
                        print(f"Warning: Could not convert loss value '{task['vae_loss']}' to float")
                        loss_values.append(0.0)
                
                average_loss = float(np.mean(loss_values)) if loss_values else 0.0
                
                # Backward transfer - safely handle numeric conversions
                backward_transfers = []
                if len(all_task_performance) > 1:
                    for task_idx in range(len(all_task_performance) - 1):
                        try:
                            initial_loss_val = all_task_performance[task_idx][task_idx]['vae_loss']
                            final_loss_val = all_task_performance[-1][task_idx]['vae_loss']
                            
                            # Convert to float safely
                            initial_loss = float(initial_loss_val) if isinstance(initial_loss_val, (int, float)) else float(str(initial_loss_val))
                            final_loss = float(final_loss_val) if isinstance(final_loss_val, (int, float)) else float(str(final_loss_val))
                            
                            backward_transfer = initial_loss - final_loss  # Lower loss is better
                            backward_transfers.append(backward_transfer)
                        except (ValueError, TypeError, KeyError) as e:
                            print(f"Warning: Could not calculate backward transfer for task {task_idx}: {e}")
                            backward_transfers.append(0.0)
                
                avg_backward_transfer = float(np.mean(backward_transfers)) if backward_transfers else 0.0
                
                # Forgetting - safely handle numeric conversions
                forgetting_scores = []
                for task_idx in range(len(all_task_performance) - 1):
                    try:
                        min_loss_val = all_task_performance[task_idx][task_idx]['vae_loss']
                        final_loss_val = all_task_performance[-1][task_idx]['vae_loss']
                        
                        # Convert to float safely
                        min_loss = float(min_loss_val) if isinstance(min_loss_val, (int, float)) else float(str(min_loss_val))
                        final_loss = float(final_loss_val) if isinstance(final_loss_val, (int, float)) else float(str(final_loss_val))
                        
                        forgetting = final_loss - min_loss  # Increase in loss is forgetting
                        forgetting_scores.append(max(0.0, forgetting))
                    except (ValueError, TypeError, KeyError) as e:
                        print(f"Warning: Could not calculate forgetting for task {task_idx}: {e}")
                        forgetting_scores.append(0.0)
                
                avg_forgetting = float(np.mean(forgetting_scores)) if forgetting_scores else 0.0
                
                return {
                    'average_loss': average_loss,
                    'backward_transfer': avg_backward_transfer,
                    'forgetting': avg_forgetting,
                    'num_tasks': len(all_task_performance)
                }

        # API/DB Helper Functions
        def get_retry_session():
            retry_strategy = Retry(
                total=3,  # Reduced retries to avoid amplifying large header issues
                status_forcelist=[500, 502, 503, 504],
                backoff_factor=1
            )
            adapter = HTTPAdapter(max_retries=retry_strategy)
            session = requests.Session()
            session.mount("https://", adapter)
            session.mount("http://", adapter)
            
            # Configure session for large headers/tokens
            session.headers.update({
                'User-Agent': 'nesy-factory-vae-rlaf/1.0'  # Short user agent
            })
            
            return session

        def trigger_pipeline(config, pipeline_domain, dqn_params=None):
            http = get_retry_session()
            url = f"{pipeline_domain}/bob-service-test/v1.0/pipeline/trigger/ml?pipelineId={config['pipeline_id']}"
            
            # Prepare minimal payload to reduce request size
            pipeline_params = {"param_json": json.dumps(dqn_params)} if dqn_params else {}
            payload = {
                "pipelineType": "ML", 
                "containerResources": {}, 
                "experimentId": config['experiment_id'],
                "enableCaching": True, 
                "parameters": pipeline_params, 
                "version": 1
            }
            
            # Convert to JSON string
            payload_json = json.dumps(payload, separators=(',', ':'))  # Compact JSON
            
            print(f"Triggering DQN pipeline with URL: {url}")
            print(f"Payload size: {len(payload_json)} bytes")
            print(f"Payload preview: {payload_json[:200]}...")
            
            # Use minimal headers to reduce request size
            headers = {
                'accept': 'application/json', 
                'Authorization': f"Bearer {config['access_token'][:50]}..." if len(config['access_token']) > 50 else f"Bearer {config['access_token']}",  # Log only first 50 chars
                'Content-Type': 'application/json'
            }
            
            # Actual headers for request (with full token)
            actual_headers = {
                'accept': 'application/json', 
                'Authorization': f"Bearer {config['access_token']}",
                'Content-Type': 'application/json'
            }
            
            print(f"Authorization token length: {len(config['access_token'])} characters")
            
            try:
                # Try with minimal headers first
                response = http.post(url, headers=actual_headers, data=payload_json, timeout=60)
                print(f"HTTP Response Status: {response.status_code}")
                
                if response.status_code == 400:
                    response_text = response.text
                    print(f"400 Error Response: {response_text}")
                    
                    if "Request Header Or Cookie Too Large" in response_text:
                        print("Token too large error detected. Trying alternative approaches...")
                        
                        # Try 1: Remove extra headers
                        minimal_headers = {
                            'Authorization': f"Bearer {config['access_token']}",
                            'Content-Type': 'application/json'
                        }
                        
                        print("Retrying with minimal headers...")
                        response = http.post(url, headers=minimal_headers, data=payload_json, timeout=60)
                        print(f"Retry Response Status: {response.status_code}")
                        
                        if response.status_code == 400 and "Request Header Or Cookie Too Large" in response.text:
                            # Try 2: Use POST with token in body instead of header
                            print("Trying token in request body...")
                            payload_with_token = payload.copy()
                            payload_with_token['access_token'] = config['access_token']
                            
                            body_headers = {
                                'Content-Type': 'application/json'
                            }
                            
                            response = http.post(url, headers=body_headers, 
                                               data=json.dumps(payload_with_token, separators=(',', ':')), 
                                               timeout=60)
                            print(f"Body token Response Status: {response.status_code}")
                            
                            if response.status_code == 400:
                                print("All token size workarounds failed. The token may be too large for this API.")
                                print("Consider using a shorter-lived or different token.")
                
                if response.status_code not in [200, 201]:
                    print(f"Pipeline trigger failed with status {response.status_code}")
                    print(f"Response text: {response.text}")
                    response.raise_for_status()
                
                response_json = response.json()
                print(f"Triggered pipeline successfully. Response: {response_json}")
                
                if 'runId' not in response_json:
                    raise RuntimeError(f"No runId in response: {response_json}")
                    
                return response_json['runId']
                
            except requests.exceptions.RequestException as e:
                print(f"Request failed: {e}")
                if hasattr(e, 'response') and e.response is not None:
                    print(f"Error response status: {e.response.status_code}")
                    print(f"Error response text: {e.response.text}")
                raise
            except json.JSONDecodeError as e:
                print(f"Failed to parse JSON response: {e}")
                print(f"Response text: {response.text}")
                raise
            except Exception as e:
                print(f"Unexpected error during pipeline trigger: {e}")
                raise

        def get_pipeline_status(config, pipeline_domain):
            http = get_retry_session()
            url = f"{pipeline_domain}/bob-service-test/v1.0/pipeline/{config['pipeline_id']}/status/ml/{config['run_id']}"
            
            # Use minimal headers to avoid "Request Header Too Large" error
            headers = {
                'accept': 'application/json', 
                'Authorization': f"Bearer {config['access_token']}"
            }
            
            try:
                response = http.get(url, headers=headers, timeout=60)
                print(f"Status check HTTP Response: {response.status_code}")
                
                if response.status_code == 400 and "Request Header Or Cookie Too Large" in response.text:
                    print("Token too large for status check. Trying alternative...")
                    # For status checks, we might need to use a different approach
                    # This depends on your API design - you might need to use query parameters
                    # or find an alternative status endpoint
                    print("Status check failed due to token size. Using fallback status.")
                    return "RUNNING"  # Assume still running if we can't check
                
                if response.status_code not in [200, 201]:
                    print(f"Status check failed with status {response.status_code}")
                    print(f"Response text: {response.text}")
                    response.raise_for_status()
                
                pipeline_status = response.json()
                print(f"Pipeline status response size: {len(str(pipeline_status))} characters")
                
                if 'run_details' not in pipeline_status or 'state_history' not in pipeline_status['run_details']:
                    raise RuntimeError(f"Invalid pipeline status response structure: {pipeline_status}")
                
                state_history = pipeline_status['run_details']['state_history']
                if not state_history:
                    raise RuntimeError("Empty state history in pipeline status")
                    
                latest_state = state_history[-1]
                current_status = latest_state['state']
                print(f"Current pipeline status: {current_status}")
                
                return current_status
                
            except requests.exceptions.RequestException as e:
                print(f"Status check request failed: {e}")
                if hasattr(e, 'response') and e.response is not None and e.response.status_code == 400:
                    print("Assuming pipeline is still running due to status check failure")
                    return "RUNNING"
                raise
            except json.JSONDecodeError as e:
                print(f"Failed to parse status response JSON: {e}")
                print(f"Response text: {response.text}")
                raise
            except Exception as e:
                print(f"Unexpected error during status check: {e}")
                raise

        def get_instance(access_token, domain, schema_id, model_id):
            http = get_retry_session()
            url = f"{domain}/pi-entity-instances-service/v3.0/schemas/{schema_id}/instances/list"
            headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}
            payload = {"dbType": "TIDB", "ownedOnly": True, "filter": {"model_id": model_id}}
            response = http.post(url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            print(f"Full response from get_instance: {response.json()}")
            return response.json()['content'][0]

        def update_instance_field(access_token, domain, schema_id, model_id, field, value):
            http = get_retry_session()
            url = f"{domain}/pi-entity-instances-service/v2.0/schemas/{schema_id}/instances"
            headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}
            payload = {
                "dbType": "TIDB",
                "conditionalFilter": {"conditions": [{"field": "model_id", "operator": "EQUAL", "value": model_id}]},
                "partialUpdateRequests": [{"patch": [{"operation": "REPLACE", "path": f"{field}", "value": value}]}]
            }
            print("cURL command for update_instance_field")
            headers_str = " ".join([f"-H '{k}: {v}'" for k, v in headers.items()])
            print(f"curl -X PATCH '{url}' {headers_str} -d '{json.dumps(payload)}'")    
            response = http.patch(url, headers=headers, data=json.dumps(payload), timeout=30)
            response.raise_for_status()
            print(f"Full response from update_instance_field: {response.json()}")
            print(f"Successfully updated field '{field}' for model_id '{model_id}'")

        # Core Logic
        def trigger_and_wait_for_dqn_pipeline(config, pipeline_domain, dqn_params):
            print(f"Starting DQN pipeline trigger process...")
            print(f"Pipeline ID: {config['pipeline_id']}")
            print(f"Experiment ID: {config['experiment_id']}")
            print(f"Pipeline Domain: {pipeline_domain}")
            print(f"DQN Parameters: {json.dumps(dqn_params, indent=2)}")
            
            try:
                run_id = trigger_pipeline(config, pipeline_domain, dqn_params)
                config["run_id"] = run_id
                print(f"DQN pipeline triggered successfully with run_id: {run_id}")
                
                max_wait_time = 1800  # 30 minutes maximum wait time
                wait_interval = 60    # Check every 60 seconds
                elapsed_time = 0
                
                while elapsed_time < max_wait_time:
                    try:
                        status = get_pipeline_status(config, pipeline_domain)
                        print(f"Current DQN pipeline status: {status} (waited {elapsed_time}s)")
                        
                        if status == 'SUCCEEDED':
                            print("DQN Pipeline execution completed successfully.")
                            return True
                        elif status in ['FAILED', 'ERROR', 'CANCELLED']:
                            raise RuntimeError(f"DQN Pipeline failed with status: {status}")
                        elif status in ['RUNNING', 'PENDING', 'QUEUED']:
                            print(f"Pipeline still {status.lower()}, waiting...")
                        else:
                            print(f"Unknown pipeline status: {status}, continuing to wait...")
                        
                        time.sleep(wait_interval)
                        elapsed_time += wait_interval
                        
                    except Exception as status_error:
                        print(f"Error checking pipeline status: {status_error}")
                        if elapsed_time > 300:  # After 5 minutes, give up on status errors
                            raise RuntimeError(f"Persistent status check failures: {status_error}")
                        time.sleep(wait_interval)
                        elapsed_time += wait_interval
                
                raise RuntimeError(f"DQN Pipeline timed out after {max_wait_time} seconds")
                
            except Exception as e:
                print(f"DQN pipeline execution failed: {e}")
                raise

        def model_retraining(action, model_path, data_path, config_path, tasks_path, output_model_path, previous_metrics, dqn_params):
            # Load VAE model architecture
            from nesy_factory.VAE import create_vae_model
            
            with open(config_path, 'r') as f: 
                config = json.load(f)
            with open(tasks_path, "rb") as f: 
                tasks = pickle.load(f)
            
            config.update(action)
            
            # Create VAE model
            vae_type = config.get('vae_type', 'standard_vae')
            model = create_vae_model(vae_type, config)
            
            # Load trained weights with fallback architecture handling
            state_dict = torch.load(model_path, map_location=torch.device('cpu'))
            
            try:
                # Try loading directly first
                model.load_state_dict(state_dict, strict=True)
                print("Successfully loaded model with exact architecture match")
            except RuntimeError as e:
                print(f"Architecture mismatch, trying flexible loading: {e}")
                try:
                    # Try non-strict loading
                    model.load_state_dict(state_dict, strict=False)
                    print("Successfully loaded model with non-strict mode")
                except Exception as e2:
                    print(f"Non-strict loading failed: {e2}")
                    # Create fallback model that matches the saved weights architecture
                    print("Creating fallback model architecture to match saved weights")
                    
                    # Analyze the saved state dict to understand the architecture
                    saved_keys = list(state_dict.keys())
                    print(f"Saved model keys: {saved_keys}")
                    
                    # Create a simple StandardVAE that matches the saved architecture
                    import torch.nn as nn
                    
                    class CompatibleStandardVAE(nn.Module):
                        def __init__(self, input_dim, latent_dim, hidden_dims=None):
                            super().__init__()
                            self.vae_type = 'standard_vae'
                            self.input_dim = input_dim
                            self.latent_dim = latent_dim
                            
                            if hidden_dims is None:
                                hidden_dims = [512, 256]
                            
                            # Build encoder matching saved architecture
                            encoder_layers = []
                            prev_dim = input_dim
                            for hidden_dim in hidden_dims:
                                encoder_layers.extend([
                                    nn.Linear(prev_dim, hidden_dim),
                                    nn.ReLU()
                                ])
                                prev_dim = hidden_dim
                            
                            self.encoder = nn.Sequential(*encoder_layers)
                            
                            # Latent layers - match saved naming
                            if 'mu_layer.weight' in saved_keys:
                                self.mu_layer = nn.Linear(prev_dim, latent_dim)
                                self.logvar_layer = nn.Linear(prev_dim, latent_dim)
                            else:
                                self.fc_mu = nn.Linear(prev_dim, latent_dim) 
                                self.fc_log_var = nn.Linear(prev_dim, latent_dim)
                            
                            # Build decoder
                            decoder_layers = []
                            prev_dim = latent_dim
                            for hidden_dim in reversed(hidden_dims):
                                decoder_layers.extend([
                                    nn.Linear(prev_dim, hidden_dim),
                                    nn.ReLU()
                                ])
                                prev_dim = hidden_dim
                            
                            decoder_layers.append(nn.Linear(prev_dim, input_dim))
                            decoder_layers.append(nn.Sigmoid())
                            
                            self.decoder = nn.Sequential(*decoder_layers)
                        
                        def encode(self, x):
                            h = self.encoder(x)
                            if hasattr(self, 'mu_layer'):
                                return self.mu_layer(h), self.logvar_layer(h)
                            else:
                                return self.fc_mu(h), self.fc_log_var(h)
                        
                        def reparameterize(self, mu, logvar):
                            std = torch.exp(0.5 * logvar)
                            eps = torch.randn_like(std)
                            return mu + eps * std
                        
                        def decode(self, z):
                            return self.decoder(z)
                        
                        def forward(self, x):
                            mu, logvar = self.encode(x)
                            z = self.reparameterize(mu, logvar)
                            recon_x = self.decode(z)
                            return recon_x, mu, logvar
                    
                    # Create compatible model
                    input_dim = config.get('input_dim', 784)  # Default MNIST size
                    latent_dim = config.get('latent_dim', 128)
                    model = CompatibleStandardVAE(input_dim, latent_dim)
                    
                    # Try loading again
                    try:
                        model.load_state_dict(state_dict, strict=False)
                        print("Successfully loaded model with compatible architecture")
                    except Exception as e3:
                        print(f"Even compatible loading failed: {e3}")
                        print("Using randomly initialized model")
                        # Keep the randomly initialized model
            
            print("Starting VAE continual learning experiments")
            trainer = ContinualVAETrainer(config)
            continual_strategies = ['naive']
            
            results = trainer.train_continual_vae(tasks=tasks, strategies=continual_strategies, model=model)
            print(f"VAE continual learning results: {results}")
            
            average_eval_metrics = results['naive']['average_eval_metrics']
            
            # Compare with previous metrics (lower loss is better for VAE)
            improvement_score = 0.0
            for param in dqn_params:
                key = param['key']
                sign = 1 if param['sign'] == '+' else -1
                if key in average_eval_metrics and key in previous_metrics:
                    try:
                        # Ensure both values are numeric
                        current_val = float(average_eval_metrics[key])
                        previous_val = float(previous_metrics[key])
                        improvement = (current_val - previous_val) * sign
                        improvement_score += improvement
                        print(f"Metric {key}: {previous_val:.4f} -> {current_val:.4f}, improvement: {improvement:.4f}")
                    except (ValueError, TypeError) as e:
                        print(f"Warning: Could not compute improvement for metric '{key}': {e}")
                        continue

            if improvement_score > 0:
                print(f"VAE metrics improved (score: {improvement_score:.4f}). Saving model.")
                os.makedirs(os.path.dirname(output_model_path), exist_ok=True)
                final_model = results['naive']['final_model']
                torch.save(final_model.state_dict(), output_model_path)
                print(f"Saved retrained VAE model to {output_model_path}")
            else:
                print(f"No improvement in VAE metrics (score: {improvement_score:.4f}). Model not saved.")
                os.makedirs(os.path.dirname(output_model_path), exist_ok=True)
                # Create a dummy file to satisfy Kubeflow output requirements
                with open(output_model_path, 'w') as f:
                    f.write("VAE model not saved due to lack of improvement.")

            # Ensure all metrics are JSON serializable
            serializable_metrics = {}
            for key, value in average_eval_metrics.items():
                try:
                    if isinstance(value, (int, float, bool)):
                        serializable_metrics[key] = float(value)
                    elif isinstance(value, str):
                        try:
                            serializable_metrics[key] = float(value)
                        except ValueError:
                            serializable_metrics[key] = str(value)
                    else:
                        serializable_metrics[key] = str(value)
                except Exception as e:
                    print(f"Warning: Could not serialize metric '{key}': {e}")
                    serializable_metrics[key] = 0.0

            return {"metrics": serializable_metrics, "model_path": output_model_path}

        # Main Execution
        def main():
            parser = argparse.ArgumentParser()
            parser.add_argument('--trained_model', type=str, required=True)
            parser.add_argument('--init_metrics', type=str, required=True)
            parser.add_argument('--rlaf_output', type=str, required=True)
            parser.add_argument('--data_path', type=str, required=True)
            parser.add_argument('--config', type=str, required=True)
            parser.add_argument('--domain', type=str, required=True)
            parser.add_argument('--schema_id', type=str, required=True)
            parser.add_argument('--model_id', type=str, required=True)
            parser.add_argument('--dqn_pipeline_id', type=str, required=True)
            parser.add_argument('--dqn_experiment_id', type=str, required=True)
            parser.add_argument('--access_token', type=str, required=True)
            parser.add_argument('--tasks', type=str, required=True)
            parser.add_argument('--pipeline_domain', type=str, required=True)
            parser.add_argument('--retrained_model', type=str, required=True)
            args = parser.parse_args()

            with open(args.access_token, 'r') as f:
                access_token = f.read().strip()
            with open(args.init_metrics, 'r') as f:
                current_metrics = json.load(f)
 
            action_id_for_next_pierce = -1
 
            for i in range(2):
                print(f"VAE RLAF Loop Iteration {i+1}")
                
                cleaned_metrics = {}
                dqn_params = []
                for key, value in current_metrics.items():
                    try:
                        # Handle different types of values
                        if isinstance(value, (int, float)):
                            numeric_value = float(value)
                        elif isinstance(value, str):
                            numeric_value = float(value)
                        elif hasattr(value, 'item'):  # Handle numpy scalars
                            numeric_value = float(value.item())
                        else:
                            # Try to convert to float
                            numeric_value = float(str(value))
                        
                        cleaned_metrics[key] = numeric_value
                        
                        if "loss" in key.lower():
                            dqn_params.append({"key": key, "sign": "-", "mul": 1.0})  # Lower loss is better
                        elif "accuracy" in key.lower() or "f1" in key.lower():
                            dqn_params.append({"key": key, "sign": "+", "mul": 1.0})  # Higher accuracy is better
                    except (ValueError, TypeError) as e:
                        print(f"Warning: Could not convert VAE metric '{key}' with value '{value}' (type: {type(value)}) to float: {e}. Skipping.")
                
                print(f"Dynamically generated param_json for VAE DQN: {json.dumps(dqn_params)}")

                instance = get_instance(access_token, args.domain, args.schema_id, args.model_id)
                print(f"Instance data: {instance}")
                
                if instance.get('pierce2rlaf'):
                    latest_pierce2rlaf = instance['pierce2rlaf'][-1]
                    previous_state = latest_pierce2rlaf['current_state']
                    episode = latest_pierce2rlaf['episode']
                else:
                    previous_state = {key: 0.0 for key in cleaned_metrics.keys()}
                    episode = 0
 
                new_pierce2rlaf_entry = {
                    "action_id": action_id_for_next_pierce, 
                    "previous_state": previous_state,
                    "current_state": cleaned_metrics, 
                    "episode": episode, 
                    "timestamp": int(time.time())
                }
                pierce2rlaf_history = instance.get("pierce2rlaf", [])
                pierce2rlaf_history.append(new_pierce2rlaf_entry)
                update_instance_field(access_token, args.domain, args.schema_id, args.model_id, "pierce2rlaf", pierce2rlaf_history)

                dqn_config = {
                    "pipeline_id": args.dqn_pipeline_id, 
                    "experiment_id": args.dqn_experiment_id, 
                    "access_token": access_token
                }
                print(f"DQN config: {dqn_config}")
                
                try:
                    # Try to trigger the actual DQN pipeline
                    print(f"Attempting to trigger DQN pipeline: {args.dqn_pipeline_id}")
                    trigger_and_wait_for_dqn_pipeline(dqn_config, args.pipeline_domain, dqn_params)
                    print("DQN pipeline completed successfully")
                    
                    # Get updated instance with rlaf2pierce response
                    updated_instance = get_instance(access_token, args.domain, args.schema_id, args.model_id)
                    rlaf2pierce_history = updated_instance.get('rlaf2pierce', [])
                    
                    if rlaf2pierce_history:
                        latest_rlaf2pierce = rlaf2pierce_history[-1]
                        print(f"Received DQN pipeline response: {latest_rlaf2pierce}")
                    else:
                        print("No rlaf2pierce response found, using simulation")
                        latest_rlaf2pierce = {
                            "action_id": 0,
                            "pierce_or_not": True,
                            "current_state": cleaned_metrics,
                            "previous_state": previous_state,
                            "timestamp": int(time.time())
                        }
                        
                except Exception as e:
                    print(f"DQN pipeline triggering failed: {e}")
                    print("Falling back to simulation mode")
                    
                    # Fallback: simulate DQN response by selecting a random action
                    import random
                    rlaf_actions = instance.get('rlaf_actions', {}).get('actions', [])
                    if rlaf_actions:
                        action_id_for_next_pierce = random.choice(rlaf_actions)['id']
                        print(f"Simulated DQN action selection: {action_id_for_next_pierce}")
                    else:
                        action_id_for_next_pierce = 0
                        print("No RLAF actions available, using action 0")

                    # Simulate updated instance with mock rlaf2pierce response
                    latest_rlaf2pierce = {
                        "action_id": action_id_for_next_pierce,
                        "pierce_or_not": True,  # Set to False to stop after first iteration
                        "current_state": cleaned_metrics,
                        "previous_state": previous_state,
                        "timestamp": int(time.time())
                    }
                
                if not latest_rlaf2pierce.get("pierce_or_not", True):
                    print("pierce_or_not is false. Exiting VAE RLAF loop.")
                    break
                    
                print(f"RLAF2Pierce response: {latest_rlaf2pierce}")
                rlaf_actions = instance.get('rlaf_actions', {}).get('actions', [])
                action_id_for_next_pierce = latest_rlaf2pierce['action_id']
                action_details = next((a for a in rlaf_actions if a["id"] == action_id_for_next_pierce), None)
                if not action_details:
                    # Fallback: use the first available action if the selected one doesn't exist
                    if rlaf_actions:
                        action_details = rlaf_actions[0]
                        print(f"Action ID {action_id_for_next_pierce} not found, using fallback: {action_details}")
                    else:
                        print("No RLAF actions available, creating default action")
                        action_details = {
                            "id": 0,
                            "name": "Default_Action",
                            "params": {"epochs": 2, "error_absolute_threshold": 0.03}
                        }
 
                print(f"DQN pipeline recommended VAE action: {action_details}. Retraining VAE model.")
                retraining_results = model_retraining(
                    action_details['params'], args.trained_model, args.data_path, args.config, args.tasks,
                    args.retrained_model, previous_state, dqn_params
                )
                current_metrics = retraining_results["metrics"]

            # Ensure output directories exist and create proper output files
            os.makedirs(os.path.dirname(args.rlaf_output), exist_ok=True)
            
            # Ensure all final metrics are properly serializable
            final_output = {}
            for key, value in current_metrics.items():
                try:
                    if isinstance(value, (int, float, bool)):
                        final_output[key] = float(value)
                    elif isinstance(value, str):
                        try:
                            final_output[key] = float(value)
                        except ValueError:
                            final_output[key] = str(value)
                    elif hasattr(value, 'item'):  # Handle numpy scalars
                        final_output[key] = float(value.item())
                    else:
                        final_output[key] = str(value)
                except Exception as e:
                    print(f"Warning: Could not serialize final metric '{key}': {e}")
                    final_output[key] = 0.0
            
            with open(args.rlaf_output, 'w') as f:
                json.dump({"final_metrics": final_output}, f, indent=4)
            print(f"VAE RLAF loop finished. Final parameters written to {args.rlaf_output}")
            
            # Ensure retrained model output exists (Kubeflow requirement)
            if not os.path.exists(args.retrained_model):
                os.makedirs(os.path.dirname(args.retrained_model), exist_ok=True)
                with open(args.retrained_model, 'w') as f:
                    f.write("Retrained model path placeholder")

        if __name__ == '__main__':
            main()
    args:
      - --trained_model
      - {inputPath: trained_model}
      - --init_metrics
      - {inputPath: init_metrics}
      - --rlaf_output
      - {outputPath: rlaf_output}
      - --data_path
      - {inputPath: data_path}
      - --config
      - {inputPath: config}
      - --domain
      - {inputValue: domain}
      - --schema_id
      - {inputValue: schema_id}
      - --model_id
      - {inputValue: model_id}
      - --dqn_pipeline_id
      - {inputValue: dqn_pipeline_id}
      - --dqn_experiment_id
      - {inputValue: dqn_experiment_id}
      - --access_token
      - {inputPath: access_token}
      - --tasks
      - {inputPath: tasks}
      - --pipeline_domain
      - {inputValue: pipeline_domain}
      - --retrained_model
      - {outputPath: retrained_model}
