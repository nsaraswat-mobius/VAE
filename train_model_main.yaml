name: Train VAE Model
description: Trains the VAE model for failure signature anomaly detection.
inputs:
  - {name: model, type: Model}
  - {name: train_loader, type: Dataset}
  - {name: config, type: String}
outputs:
  - {name: trained_model, type: Model}
implementation:
  container:
    image: nikhilv215/nesy-factory:v22
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import json
        import os
        import pickle
        import sys
        import numpy as np
        import torch
        import torch.nn as nn
        import torch.optim as optim
        
        from nesy_factory.VAE.standard_vae import StandardVAE
        from nesy_factory.VAE.beta_vae import BetaVAE
        from nesy_factory.VAE.conditional_vae import ConditionalVAE

        parser = argparse.ArgumentParser()
        parser.add_argument('--model', type=str, required=True)
        parser.add_argument('--train_loader', type=str, required=True)
        parser.add_argument('--config', type=str, required=True)
        parser.add_argument('--trained_model', type=str, required=True)
        args = parser.parse_args()

        config = json.loads(args.config)

        # Load the model
        with open(args.model, 'rb') as f:
            model_obj = pickle.load(f)

        # Load the training data (handle new format with metadata)
        with open(args.train_loader, 'rb') as f:
            train_data = pickle.load(f)
            
        # Handle both old format (just loader) and new format (with metadata)
        if isinstance(train_data, dict) and 'loader' in train_data:
            train_loader_obj = train_data['loader']
            metadata = train_data['metadata']
            print(f"Loaded training data with metadata:")
            print(f"  - Input dimension: {metadata['processed_input_dim']}")
            print(f"  - Train samples: {metadata['train_samples']}")
            print(f"  - Batch size: {metadata['batch_size']}")
        else:
            # Old format compatibility or direct loader
            train_loader_obj = train_data
            metadata = None
            print("Loaded training data (legacy format without metadata)")

        # Set up training parameters
        learning_rate = config.get('learning_rate', 0.001)
        epochs = config.get('epochs', 100)
        beta = config.get('beta', 1.0)
        
        # Set up optimizer
        optimizer = optim.Adam(model_obj.parameters(), lr=learning_rate)
        
        # Move model to device
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model_obj = model_obj.to(device)
        
        print(f"Training VAE on device: {device}")
        print(f"Training configuration:")
        print(f"  - Learning rate: {learning_rate}")
        print(f"  - Epochs: {epochs}")
        print(f"  - Beta (KL weight): {beta}")

        # Validate model input dimension
        print("Validating model architecture against data dimensions...")
        sample_batch = next(iter(train_loader_obj))
        print(f"Sample batch type: {type(sample_batch)}")
        
        if isinstance(sample_batch, (list, tuple)) and len(sample_batch) >= 1:
            sample_data = sample_batch[0]
            print(f"Sample data type: {type(sample_data)}")
        else:
            sample_data = sample_batch
            print(f"Sample data type (direct): {type(sample_data)}")
        
        # Check if sample_data is a tensor
        if hasattr(sample_data, 'shape'):
            actual_input_dim = sample_data.shape[1]
            print(f"Actual data input dimension: {actual_input_dim}")
        elif isinstance(sample_data, (list, np.ndarray)):
            # Try to convert to tensor
            sample_data = torch.tensor(sample_data, dtype=torch.float32)
            actual_input_dim = sample_data.shape[1]
            print(f"Converted to tensor. Actual data input dimension: {actual_input_dim}")
        else:
            print(f"Error: sample_data is not a tensor. Type: {type(sample_data)}, Value: {sample_data}")
            raise ValueError(f"Expected tensor data but got {type(sample_data)}")
        
        # Test forward pass
        try:
            model_obj.eval()
            with torch.no_grad():
                test_output = model_obj(sample_data[:1].to(device))
                print(f"Model output type: {type(test_output)}")
                if isinstance(test_output, tuple):
                    print(f"Model output length: {len(test_output)}")
            print("Model architecture validation: PASSED")
            model_obj.train()
        except RuntimeError as e:
            if "cannot be multiplied" in str(e):
                raise RuntimeError(f"Model input dimension mismatch: {e}")
            else:
                raise e

        print(f"Starting VAE Model Training...")

        # Training loop
        model_obj.train()
        for epoch in range(epochs):
            total_loss = 0
            total_recon_loss = 0
            total_kl_loss = 0
            num_batches = 0
            
            for batch_data in train_loader_obj:
                # Extract data from batch
                if isinstance(batch_data, (list, tuple)) and len(batch_data) >= 1:
                    data = batch_data[0]
                else:
                    data = batch_data
                
                data = data.to(device)
                optimizer.zero_grad()
                
                # Forward pass with flexible output handling
                vae_output = model_obj(data)
                
                # Handle different VAE output formats
                if isinstance(vae_output, dict):
                    # Dictionary output format - extract keys
                    possible_recon_keys = ['reconstruction', 'recon', 'x_recon', 'decoded', 'output']
                    possible_mu_keys = ['mu', 'mean', 'latent_mean', 'z_mean']
                    possible_logvar_keys = ['logvar', 'log_var', 'latent_logvar', 'z_logvar', 'log_variance']
                    
                    # Find reconstruction
                    recon_data = None
                    for key in possible_recon_keys:
                        if key in vae_output:
                            recon_data = vae_output[key]
                            break
                    
                    # Find mu
                    mu = None
                    for key in possible_mu_keys:
                        if key in vae_output:
                            mu = vae_output[key]
                            break
                    
                    # Find logvar
                    logvar = None
                    for key in possible_logvar_keys:
                        if key in vae_output:
                            logvar = vae_output[key]
                            break
                    
                    # Debug: print available keys if we can't find expected ones
                    if recon_data is None or mu is None or logvar is None:
                        print(f"VAE output keys: {list(vae_output.keys())}")
                        # Use first available values or create defaults
                        if recon_data is None:
                            recon_data = list(vae_output.values())[0] if vae_output else data
                        if mu is None:
                            mu = torch.zeros(data.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                        if logvar is None:
                            logvar = torch.zeros(data.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                            
                elif isinstance(vae_output, tuple):
                    if len(vae_output) == 3:
                        # Standard format: (recon_data, mu, logvar)
                        recon_data, mu, logvar = vae_output
                    elif len(vae_output) == 4:
                        # Some VAEs return 4 values: handle gracefully
                        print(f"Warning: VAE returned {len(vae_output)} values, using first 3")
                        recon_data, mu, logvar = vae_output[0], vae_output[1], vae_output[2]
                    elif len(vae_output) == 2:
                        # Some return (recon_data, latent_params)
                        recon_data, latent_params = vae_output
                        if isinstance(latent_params, tuple) and len(latent_params) >= 2:
                            mu, logvar = latent_params[0], latent_params[1]
                        else:
                            # Create dummy latent variables
                            mu = torch.zeros(data.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                            logvar = torch.zeros(data.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                    else:
                        # Unexpected tuple length - use first element as reconstruction
                        recon_data = vae_output[0]
                        mu = torch.zeros(data.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                        logvar = torch.zeros(data.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                else:
                    # Single output - assume it's reconstructed data
                    recon_data = vae_output
                    mu = torch.zeros(data.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                    logvar = torch.zeros(data.size(0), getattr(model_obj, 'latent_dim', 16)).to(device)
                
                # Calculate losses
                recon_loss = nn.MSELoss()(recon_data, data)
                kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
                kl_loss = kl_loss / data.size(0)  # Normalize by batch size
                
                # Total loss
                loss = recon_loss + beta * kl_loss
                
                # Backward pass and optimization
                loss.backward()
                optimizer.step()
                
                # Accumulate losses for logging
                total_loss += loss.item()
                total_recon_loss += recon_loss.item()
                total_kl_loss += kl_loss.item()
                num_batches += 1
            
            # Calculate average losses
            if num_batches > 0:
                avg_loss = total_loss / num_batches
                avg_recon_loss = total_recon_loss / num_batches
                avg_kl_loss = total_kl_loss / num_batches
                
                # Print training progress
                print(f"Epoch {epoch+1:3d}/{epochs} | " +
                      f"Total Loss: {avg_loss:.6f} | " +
                      f"Recon Loss: {avg_recon_loss:.6f} | " +
                      f"KL Loss: {avg_kl_loss:.6f}")
            
            # Simple divergence check
            if epoch > 10 and avg_loss > 1000:
                print("Warning: Loss is diverging, stopping training early")
                break
        
        print("Finished VAE Model Training")
        
        # Save the trained model
        os.makedirs(os.path.dirname(args.trained_model), exist_ok=True)
        with open(args.trained_model, 'wb') as f:
            pickle.dump(model_obj.cpu(), f)
        
        print(f"Saved trained VAE model to {args.trained_model}")
        
        # Print final model statistics
        total_params = sum(p.numel() for p in model_obj.parameters())
        trainable_params = sum(p.numel() for p in model_obj.parameters() if p.requires_grad)
        print(f"Model statistics:")
        print(f"  - Total parameters: {total_params}")
        print(f"  - Trainable parameters: {trainable_params}")
        print(f"  - Final training loss: {avg_loss:.6f}")
    args:
      - --model
      - {inputPath: model}
      - --train_loader
      - {inputPath: train_loader}
      - --config
      - {inputValue: config}
      - --trained_model
      - {outputPath: trained_model}
